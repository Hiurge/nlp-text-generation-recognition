{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from itertools import chain, combinations, repeat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "# Spacy language model setting\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Target directory\n",
    "DIR = \"OtherLists/\"\n",
    "\n",
    "# Load from:\n",
    "aod_raw_file = DIR + 'adverbs_of_degree_raw.txt'\n",
    "all_raw_file = DIR + 'all_emotions_no_classification_raw.txt'\n",
    "btc_raw_file = DIR + 'big_theme_classification_raw.txt'\n",
    "str_raw_file = DIR + 'strong_words_raw.txt'\n",
    "ei3_raw_file = DIR + 'words_of_emotions_3_intensivities_raw.txt'\n",
    "\n",
    "# Save to:\n",
    "aod_clean_file = DIR + 'adverbs_of_degree_clean.json'\n",
    "all_clean_file = DIR + 'all_emotions_no_classification_clean.json'\n",
    "btc_clean_file = DIR + 'big_theme_classification_clean.json'\n",
    "str_clean_file = DIR + 'strong_words_clean.json'\n",
    "ei3_clean_file = DIR + 'words_of_emotions_3_intensivities_clean.json'\n",
    "\n",
    "# Group save as CSV matrice for adnotations and JSON for easy generator access:\n",
    "deep_feelining_matrix_save_file = DIR + 'deep_feeling.csv'\n",
    "deep_feelining_access_save_file = DIR + 'deep_feeling.json'\n",
    "\n",
    "def save_as_json(path, data):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['almost',\n",
       " 'absolutely',\n",
       " 'awfully',\n",
       " 'badly',\n",
       " 'barely',\n",
       " 'completely',\n",
       " 'decidedly',\n",
       " 'deeply',\n",
       " 'enough',\n",
       " 'enormously']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. I need to prepare Textfile of adverbs of degree \n",
    "# ----------------------------------------------------------\n",
    "# it should be usefull for generating texts with action vibe \n",
    "# (source: https://www.englishclub.com/vocabulary/adverbs-degree.htm)\n",
    "\n",
    "\n",
    "# Load file\n",
    "lines_degree = open(aod_raw_file, \"r\").readlines()    \n",
    "\n",
    "# Actual preparation... Removed '\\n', '*', few lines, and showed em way to dict...\n",
    "aod_dict = {'AOD' : [line.split('\\n')[0].split('*')[0] for line in lines_degree[3:]]}\n",
    "\n",
    "save_as_json(aod_clean_file, aod_dict)\n",
    "\n",
    "\n",
    "aod_dict['AOD'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry',\n",
       " 'annoyed',\n",
       " 'afraid',\n",
       " 'awkward',\n",
       " 'affectionate',\n",
       " 'anxious',\n",
       " 'alarmed',\n",
       " 'awed',\n",
       " 'aggravated',\n",
       " 'amazed']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Lots of unclassified emotional state related words\n",
    "# -------------------------------------------------------------------------------\n",
    "# (source: https://www.verywellfamily.com/feelings-words-from-a-to-z-2086647 )\n",
    "\n",
    "\n",
    "lines_emotions = open(all_raw_file, \"r\").readlines() \n",
    "\n",
    "# Cleaned up and chained\n",
    "emotions_all = [line.lower().split('\\n')[0].split(', ') for line in lines_emotions if not len(line) < 5]\n",
    "alle = { 'AllE' : list(chain.from_iterable(emotions_all)),}\n",
    "\n",
    "save_as_json(all_clean_file, alle)\n",
    "\n",
    "\n",
    "alle['AllE'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Derailed': ['derailed', 'disjointed', 'disoriented', 'torn'],\n",
       " 'Focused': ['committed', 'complacent', 'determined', 'focused', 'inthezone'],\n",
       " 'Lost': ['baffled', 'bewildered', 'confused', 'lost', 'unfocussed'],\n",
       " 'Obsessed': ['compelled', 'consumed', 'obsessed']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['audacious', 'bold', 'brave', 'certain']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. I need to map this big messy ctr-copy/paste txt from website\n",
    "# ---------------------------------------------------------------\n",
    "# I need it to generate specific types of emotions indicators in texts \n",
    "# for NLP project. I need to map categories, subcategories, paragraphs \n",
    "# and keywords right. I dont think i need to use scraper for this one\n",
    "# (source: http://www.derose.net/steve/resources/emotionwords/ewords.html)\n",
    "\n",
    "\n",
    "\n",
    "btc = open(btc_raw_file, \"r\").readlines()\n",
    "\n",
    "\n",
    "# get & clear lines\n",
    "btc_lines = [line.split('\\n')[0] for line in btc if len(line) > 1]\n",
    "\n",
    "# get main and paragraph titles\n",
    "titles_and_lines = [ [l,\"#\",btc_lines[n+1] ] for n,l in enumerate(btc_lines) if l.split()[0].istitle()]\n",
    "\n",
    "# Main titles items & only main titles\n",
    "main_titles_items = [wlist for wlist in titles_and_lines if len(wlist[2]) < 24]\n",
    "main_titles_only = [wlist[0] for wlist in titles_and_lines if len(wlist[2]) < 24]\n",
    "\n",
    "\n",
    "si = []\n",
    "n = -1\n",
    "for fragment in titles_and_lines:\n",
    "    # Tactic: prepare moving index to join the main titles \n",
    "    # with correspon titles and with paragraphs\n",
    "    n+=1\n",
    "    if fragment[0] in main_titles_only:\n",
    "        si.append(n)\n",
    "moving_index = list(zip(si[:], (si[1:]+[100])))\n",
    "\n",
    "\n",
    "bte = {}\n",
    "for i1 ,i2 in moving_index:\n",
    "    # Now most the importan part, to get text sequences right\n",
    "    # and map titles, sections, keywords together with no mistake\n",
    "    section = titles_and_lines[i1:i2]\n",
    "    for i, paragraph in enumerate(section):\n",
    "        if i is 0:\n",
    "            \n",
    "            # seting key names as [:4] of each word in title\n",
    "            title_section = \"\".join(paragraph[0].title().split(' ')).split('/')\n",
    "            title_section = \"\".join([w[:4] for w in title_section])\n",
    "            \n",
    "            # Here comes the main container\n",
    "            bte[title_section] = {}\n",
    "            \n",
    "        else:\n",
    "            # Remove one one unneeded category i catched by appending idx 100 to moving_index (quick guess)\n",
    "            if paragraph[0] in ['Unsorted']:\n",
    "                continue\n",
    "            \n",
    "            # I might need to shorten-up acapit names also in future.\n",
    "            acapit_title = \"\".join(paragraph[0].title().split(' '))\n",
    "            \n",
    "            # Preprocess some words with accidental comas, dots\n",
    "            pattern = re.compile('[\\W_]+')\n",
    "            acapit_text = [pattern.sub('', word) for word in paragraph[2].split(', ')]\n",
    "            \n",
    "            bte[title_section][acapit_title] = acapit_text\n",
    "\n",
    "\n",
    "save_as_json(btc_clean_file, bte)\n",
    "\n",
    "display(bte['DireFocu'])\n",
    "display(bte['SafeSecu']['Fearless'][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peevish        easily irritated or annoyed\n",
      "splenetic      of or relating to the spleen\n",
      "cautious       showing careful forethought\n",
      "discreet       marked by prudence or modesty and wise self restraint\n",
      "provident      giving something useful for the future\n"
     ]
    }
   ],
   "source": [
    "# 4. Here is a 'strong words' list. Looks good for building for intensivity\n",
    "# ----------------------------------------------------\n",
    "# I just got them from a website by copy pasta again, there seem to be \n",
    "# very easy pattern (each second line or so) (checked :D yup)\n",
    "# (source: https://www.vocabulary.com/lists/152158 )\n",
    "\n",
    "\n",
    "strong_words = open(str_raw_file, \"r\").readlines()\n",
    "\n",
    "str_definitions = [re.compile('[\\W_]+').sub(' ', word).strip() for word in strong_words[1::2]]\n",
    "\n",
    "sw = {  'StrW'  : [re.compile('[\\W_]+').sub('', word) for word in strong_words[::2]],\n",
    "        'explnr': {},}\n",
    "\n",
    "for a, b in list(zip(sw['StrW'], str_definitions)):\n",
    "    sw['explnr'][a] = b\n",
    "\n",
    "\n",
    "save_as_json(str_clean_file, sw)\n",
    "\n",
    "# Ready\n",
    "#display(sw['StrW'][125:130])\n",
    "for each in sw['StrW'][125:130]:\n",
    "    print(\"{:<15}{}\".format(each, sw['explnr'][each]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awe-filled',\n",
       " 'blissful',\n",
       " 'ecstatic',\n",
       " 'egocentric',\n",
       " 'elated',\n",
       " 'enthralled',\n",
       " 'euphoric',\n",
       " 'exhilarated',\n",
       " 'giddy',\n",
       " 'jubilant']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Emotion words divided by 3 levels of intensiviy, This should be preety good\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "ei = open(ei3_raw_file, \"r\").readlines()\n",
    "            \n",
    "lines = [item.split('\\n')[0] for item in ei if len(item) > 2]\n",
    "\n",
    "ei3 = {}\n",
    "test1 = [] # For validation\n",
    "for i, line in enumerate(lines):\n",
    "    if not line[-1:].isalpha():\n",
    "        category = line\n",
    "        words = lines[i+1]\n",
    "        ei3[category] = [word.strip() for word in words.lower().split(' ~ ')]\n",
    "\n",
    "        # For testing purposes:\n",
    "        test1.append((category, len(ei3[category]))) # category name / nr of items in category \n",
    "\n",
    "\n",
    "# Sanity check: are words-in & out of equal amounts?\n",
    "test2 = [  (len(\"\".join(l.split('\\n')[0]).split(' ~ ')),  # words num check 1\n",
    "           l.count(' ~ ')+1)                              # words num check 2\n",
    "           for l in ei if l.count(' ~ ') > 0]\n",
    "# Running 3 all tests at once, also in respect to the previous:   num check 3\n",
    "for t1, t2 in list(zip(test2,test1)): \n",
    "    assert t1[0] == t1[0] == t2[1]  \n",
    "\n",
    "\n",
    "save_as_json(ei3_clean_file, ei3)\n",
    "\n",
    "ei3['Happiness3'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllE\n",
      "StrW\n",
      "AOD\n",
      "EI3\n",
      "BTE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>Source</th>\n",
       "      <th>IsEmotion</th>\n",
       "      <th>PolarGrp</th>\n",
       "      <th>PolarType</th>\n",
       "      <th>IsStrong</th>\n",
       "      <th>DegreeType</th>\n",
       "      <th>IntensityGrp</th>\n",
       "      <th>IntensityRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>abandon</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>elists</td>\n",
       "      <td>1</td>\n",
       "      <td>Atta</td>\n",
       "      <td>_Hated</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abashed</td>\n",
       "      <td>abash</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VERB</td>\n",
       "      <td>elists</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shame1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhorrence</td>\n",
       "      <td>abhorrence</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>elists</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abject</td>\n",
       "      <td>abject</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>elists</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>able</td>\n",
       "      <td>able</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>elists</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry       lemma  pos   tag  Source  IsEmotion PolarGrp PolarType  \\\n",
       "0   abandoned     abandon  VBN  VERB  elists          1     Atta    _Hated   \n",
       "1     abashed       abash  VBD  VERB  elists          1                      \n",
       "2  abhorrence  abhorrence   NN  NOUN  elists          0                      \n",
       "3      abject      abject   JJ   ADJ  elists          0                      \n",
       "4        able        able   JJ   ADJ  elists          1                      \n",
       "\n",
       "   IsStrong  DegreeType IntensityGrp IntensityRank  \n",
       "0         0           0                          0  \n",
       "1         0           0       Shame1             1  \n",
       "2         1           0                          0  \n",
       "3         1           0                          0  \n",
       "4         0           0                          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1376, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsEmotion</th>\n",
       "      <th>IsStrong</th>\n",
       "      <th>DegreeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1376.000000</td>\n",
       "      <td>1376.000000</td>\n",
       "      <td>1376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.594477</td>\n",
       "      <td>0.412791</td>\n",
       "      <td>0.037064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.492515</td>\n",
       "      <td>0.188987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IsEmotion     IsStrong   DegreeType\n",
       "count  1376.000000  1376.000000  1376.000000\n",
       "mean      0.594477     0.412791     0.037064\n",
       "std       0.491172     0.492515     0.188987\n",
       "min       0.000000     0.000000     0.000000\n",
       "25%       0.000000     0.000000     0.000000\n",
       "50%       1.000000     0.000000     0.000000\n",
       "75%       1.000000     1.000000     0.000000\n",
       "max       1.000000     1.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deep feeling JSON/dict\n",
    "# ----------------------\n",
    "# For quick use during generation\n",
    "\n",
    "DFD = {**sw, **aod_dict, **alle, **ei3}\n",
    "for k, v in bte.items():\n",
    "    DFD[k] = v\n",
    "    for kk, vv in bte[k].items():\n",
    "        DFD[\"_\"+kk] = vv\n",
    "\n",
    "save_as_json(deep_feelining_access_save_file, DFD)\n",
    "\n",
    "\n",
    "# Deep feeling CSV/pd matrice\n",
    "# ---------------------------\n",
    "# For matching in relations\n",
    "\n",
    "\n",
    "DF_map = {\n",
    "#   source      dict      specific category (column) name(s) \n",
    "#   ------      ----      ----------------------------------\n",
    "    'AllE' :    (alle,     []),\n",
    "    'StrW' :    (sw,       []),\n",
    "    'AOD'  :    (aod_dict, []),\n",
    "    'EI3'  :    (ei3,      ['IntensityGrp', 'IntensityRank']),\n",
    "    'BTE'  :    (bte,      ['PolarGrp', 'PolarType']),}\n",
    "\n",
    "base_cols = [\"Entry\", \"Source\", 'IsEmotion', 'IsStrong', 'DegreeType']\n",
    "columns_order = [ 'Entry', 'lemma', 'pos', 'tag', 'Source','IsEmotion', 'IsStrong', 'DegreeType'\n",
    "                 , 'PolarGrp', 'PolarType','IntensityGrp', 'IntensityRank' ]\n",
    "\n",
    "DATAFRAMES = []\n",
    "for name, data in DF_map.items():\n",
    "    if name is 'BTE':\n",
    "        category_words = []\n",
    "        for k in data[0].keys():\n",
    "            for kk, words in data[0][k].items():\n",
    "                category_words.append( zip([w for w in words], repeat(name), repeat(1), repeat(0), repeat(0), repeat(k), repeat(\"_\"+kk)) )\n",
    "        rows = list( chain.from_iterable( category_words))\n",
    "    \n",
    "    elif name is 'EI3':\n",
    "        rows = list( chain.from_iterable( [ zip([w for w in data[0][k]], repeat(name), repeat(1), repeat(0), repeat(0),repeat(k), repeat(k[-1])) \n",
    "                                     for k in data[0].keys()] ))\n",
    "    elif name is 'AllE':\n",
    "        rows = list(zip( data[0][name], repeat(name), repeat(1), repeat(0), repeat(0) ))\n",
    "    \n",
    "    elif name is 'StrW':\n",
    "        rows = list(zip( data[0][name], repeat(name), repeat(0), repeat(1), repeat(0) ))\n",
    "    \n",
    "    elif name is 'AOD':\n",
    "        rows = list(zip( data[0][name], repeat(name), repeat(0), repeat(0), repeat(1) ))\n",
    "    print(name)\n",
    "    \n",
    "    DF = pd.DataFrame(rows, columns=[*base_cols, *data[1]])\n",
    "    DATAFRAMES.append(DF)\n",
    "\n",
    "# Unification\n",
    "aggregation_functions = { 'IsEmotion': 'sum', 'IsStrong': 'sum', 'DegreeType': 'sum',\n",
    "                          'PolarGrp':'any', 'PolarType':'any', \n",
    "                          'IntensityGrp':'any', 'IntensityRank':'any'}\n",
    "type_cols = ['IsEmotion','IsStrong','DegreeType']\n",
    "grp_cols = ['PolarGrp', 'PolarType','IntensityGrp']\n",
    "\n",
    "DFDF = pd.concat(DATAFRAMES)\n",
    "DFDF = DFDF.groupby(DFDF['Entry']).agg(aggregation_functions)\n",
    "DFDF[type_cols] = DFDF[type_cols].applymap(lambda x: 1 if x > 0 else 0)\n",
    "DFDF[grp_cols] = DFDF[grp_cols].applymap(lambda x: x if x else '')\n",
    "DFDF['IntensityRank'] = DFDF.loc[:,'IntensityRank'].apply(lambda x: x if x else 0)\n",
    "DFDF['Source'] = 'elists'\n",
    "DFDF['Entry'] = DFDF.index.values.tolist()\n",
    "\n",
    "# Tags\n",
    "lemma = []\n",
    "pos = []\n",
    "tag = []\n",
    "for doc in nlp.pipe(DFDF.Entry.values, batch_size=50, n_threads=4):\n",
    "    if doc.is_parsed:\n",
    "        lemma.append(\" \".join([n.lemma_ for n in doc]))\n",
    "        pos.append(\" \".join([n.tag_ for n in doc]))\n",
    "        tag.append(\" \".join([n.pos_ for n in doc]))\n",
    "    else:\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        tag.append(None)\n",
    "DFDF['lemma'] = lemma\n",
    "DFDF['pos'] = pos\n",
    "DFDF['tag'] = tag\n",
    "DFDF = DFDF[columns_order]\n",
    "DFDF.index = list(range(len(DFDF)))\n",
    "# Check\n",
    "display(DFDF[:5])\n",
    "\n",
    "display(DFDF.shape)\n",
    "display(DFDF.describe())\n",
    "\n",
    "#DFDF[DFDF['Entry'].str.isalpha()!=True]\n",
    "\n",
    "# Save\n",
    "DFDF.to_csv(deep_feelining_matrix_save_file, header=columns_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
